{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mp.weixin.qq.com/s?__biz=MjM5MzY4NzE3MA==&mid=2247484652&idx=1&sn=1ab00e57d902133759044486d6ebcb3f&source=41#wechat_redirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.指定GPU编号\n",
    "os.environ['CUDA_VISIBLE_EVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.查看模型每层的输出详情\n",
    "from torchsummary import summary\n",
    "summary(your_model,input_size=(channels,H,W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.梯度裁剪\n",
    "import torch.nn as nn\n",
    "outputs = model(data)\n",
    "loss = loss_fn(outputs,target)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "nn.utils.clip_grad_norm_(model.parameters(),max_norm=20,norm_type=2)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.扩展单张图片维度\n",
    "# 方案1\n",
    "import cv2\n",
    "import torch\n",
    "image = cv2.imread(img_path)\n",
    "image = torch.tensor(image)\n",
    "print(image.size())\n",
    "img = image.view(1,*image.size())\n",
    "print(img.size())\n",
    "# 方案2\n",
    "img = image[np.newaxis,:,:,:]\n",
    "# 方案3\n",
    "img = image.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 6, 2, 5])\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 5.独热编码\n",
    "import torch\n",
    "class_num = 8\n",
    "batch_size = 4\n",
    "def one_hot(label):\n",
    "    label = label.resize_(batch_size,1)\n",
    "    m_zeros = torch.zeros(batch_size,class_num)\n",
    "    onehot = m_zeros.scatter(1,label,1)\n",
    "    return onehot.numpy()\n",
    "label = torch.LongTensor(batch_size).random_() % class_num\n",
    "print(label)\n",
    "print(one_hot(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.防止验证模型时爆显存\n",
    "with torch.no_grad():\n",
    "    # 使用model进行预测的代码\n",
    "    pass\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.学习率衰减\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "# 训练前的初始化\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer,10,0.1)\n",
    "# 训练过程中\n",
    "for n in n_epoch:\n",
    "    scheduler.step()\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.冻结某些层的参数\n",
    "net = Network() # 获取自定义网络结构\n",
    "for name,value in net.named_parameters():\n",
    "    print('name: {0},\\t grad: {1}'.format(name, value.requires_grad))\n",
    "# 假设前几层信息如下：\n",
    "name: cnn.VGG_16.convolution1_1.weight,\t grad: True\n",
    "name: cnn.VGG_16.convolution1_1.bias,\t grad: True\n",
    "name: cnn.VGG_16.convolution1_2.weight,\t grad: True\n",
    "name: cnn.VGG_16.convolution1_2.bias,\t grad: True\n",
    "name: cnn.VGG_16.convolution2_1.weight,\t grad: True\n",
    "name: cnn.VGG_16.convolution2_1.bias,\t grad: True\n",
    "name: cnn.VGG_16.convolution2_2.weight,\t grad: True\n",
    "name: cnn.VGG_16.convolution2_2.bias,\t grad: True\n",
    "# 后面的True表示该层的参数可训练，然后我们定义一个要冻结的层的列表\n",
    "no_grad = [\n",
    "    'cnn.VGG_16.convolution1_1.weight',\n",
    "    'cnn.VGG_16.convolution1_1.bias',\n",
    "    'cnn.VGG_16.convolution1_2.weight',\n",
    "    'cnn.VGG_16.convolution1_2.bias'\n",
    "]\n",
    "# 冻结方法如下\n",
    "net = Net.CTPN() # 获取网络结构\n",
    "for name,value in net.named_parameters():\n",
    "    if name in no_grad:\n",
    "        value.requires_grad = False\n",
    "    else:\n",
    "        value.requires_grad = True\n",
    "# 最后在定义优化器时，只对requires_grad为True的层的参数进行更新\n",
    "optimizer = optim.Adam(filter(lambda p:p.requires_grad,net.parameters()),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对不同层使用不同学习率\n",
    "net = Network()  # 获取自定义网络结构\n",
    "for name, value in net.named_parameters():\n",
    "    print('name: {}'.format(name))\n",
    "# 输出：\n",
    "# name: cnn.VGG_16.convolution1_1.weight\n",
    "# name: cnn.VGG_16.convolution1_1.bias\n",
    "# name: cnn.VGG_16.convolution1_2.weight\n",
    "# name: cnn.VGG_16.convolution1_2.bias\n",
    "# name: cnn.VGG_16.convolution2_1.weight\n",
    "# name: cnn.VGG_16.convolution2_1.bias\n",
    "# name: cnn.VGG_16.convolution2_2.weight\n",
    "# name: cnn.VGG_16.convolution2_2.bias\n",
    "# 对convolution1和convlution2设置不同的学习率，首先将它们分开，即放到不同的列表里\n",
    "conv1_params = []\n",
    "conv2_params = []\n",
    "for name,parms in net.named_parameters():\n",
    "    if \"convlution1\" in name:\n",
    "        conv1_params += [parms]\n",
    "    else:\n",
    "        conv2_params += [parms]\n",
    "# 然后在优化器中进行如下操作\n",
    "optimizer = optim.Adam(\n",
    "    [\n",
    "        {\"params\":conv1_params,\"lr\":0.01},\n",
    "        {\"params\":conv2_params,\"lr\":0.001},\n",
    "    ],\n",
    "    weight_decay = 1e-3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
